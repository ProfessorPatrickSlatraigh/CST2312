{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST2312/blob/main/CST2312_HD32_Spr2023_Class_12_DictionariesDecorators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sivi2IUlD10N"
      },
      "source": [
        "# **CST2312 Class12 - Dictionaries and Decorators**\n",
        "\n",
        "  - Word count with dictionaries    \n",
        "  - Anmol Tomar's Next Level Python on Decorators with a primer on foundational concepts used.     \n",
        "\n",
        "Updated content as of 07-Mar-2023   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtosZlQIczc0"
      },
      "source": [
        "*__*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dictionary Word Count Example     "
      ],
      "metadata": {
        "id": "4qmJFx9G0hcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Housekeeping    \n"
      ],
      "metadata": {
        "id": "Hrc_qewTl_6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string    # for string processing, including punctuation    \n",
        "import itertools # to take a slice of an iterable, including a dictionary slice\n",
        "import pprint    # for pretty printing of a dictionary   "
      ],
      "metadata": {
        "id": "MlrNg-rxmBx9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7fP5obdEAS3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Load and Handle    \n",
        "\n",
        "1. Take a copy of the UTF-8 text file of the book The Square Pegs by Ray Bradbury, 1948 from Professor Patrick's `data` repo on **GitHub** and load it to the current working directory with the file name `theSquarePegs.txt`.   \n",
        "\n",
        "2. Open a file handle `sqrpegs_handle` as *read-only* for the text file of the book.       "
      ],
      "metadata": {
        "id": "95SKQ_IsmC35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://raw.githubusercontent.com/ProfessorPatrickSlatraigh/data/main/theSquarePegs_RayBradbury.txt' -o 'theSquarePegs.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcECdC2omaJx",
        "outputId": "06a0fbf1-d93c-41a0-b3a7-da77e0bba12c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 22 47434   22 10498    0     0  55544      0 --:--:-- --:--:-- --:--:-- 55252\r100 47434  100 47434    0     0   236k      0 --:--:-- --:--:-- --:--:--  235k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioYbAlua1Ul"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqrpegs_handle = open('/content/theSquarePegs.txt', 'rt')"
      ],
      "metadata": {
        "id": "QcW86Ms0nZjo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate through the text    \n",
        "    \n",
        "* <u>Open the File</u>    \n",
        "1. With `open()` and skip to line #25    \n",
        "    \n",
        "* <u>Wrangle</u>\n",
        "2. Remove punctuation    \n",
        "3. Transform to lower case    \n",
        "4. Split wrangled lines into words    \n",
        "    \n",
        "* <u>Process words</u>    \n",
        "5. Drop words from fluff list of words\n",
        "6. Use dictionary and `.get()` to count instance of word    "
      ],
      "metadata": {
        "id": "d_11HjDcoU8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                                                           #5 build a list of fluff words to drop\n",
        "fluff_word_lst = ['the','to', 'of', 'and', 'a', 'in', 'you',\n",
        "                  'or', 'her', 'she', 'with', 'this', 'on',\n",
        "                  'it', 'for', 'was', 'not', 'i', 'is',\n",
        "                  'he', 'be', 'that', 'any', 'we', 'there',\n",
        "                  'are', 'at', 'by', 'from', 'do', 'be',\n",
        "                  'at', 'project', 'gutenberg',\n",
        "                  'gutenbergtm', 'they', 'as', 'them',\n",
        "                  'your', 'if', 'no', 'were',\n",
        "                  'an', 'into', 'us', 'where', 'what',\n",
        "                  'who', 'can', 'then', 'other', 'dont',\n",
        "                  'his', 'him', 'its', 'which', 'did']\n",
        "sqrpegs_words_dict = dict()                                 #6 initialize word count dictionary\n",
        "\n",
        "with open('/content/theSquarePegs.txt') as sqrpegs_handle:  #1   open the file\n",
        "    for skipped in range(25):                               #1   counting skipped lines\n",
        "        next(sqrpegs_handle)                                #1   skipping lines counted\n",
        "    for line_str in sqrpegs_handle:                         #    iterate lines to wrangle\n",
        "        # the following statement does the #2, #3, and #4 wranging and split into a list of words \n",
        "        wrangled_words = line_str.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "        for word in wrangled_words:                         #5/6 process lists of wrangled words\n",
        "            if word in fluff_word_lst:\n",
        "                continue\n",
        "            sqrpegs_words_dict[word] = sqrpegs_words_dict.get(word, 0) +1  #5 keep a count in dictionary\n",
        "            # print(word) #scaffolding"
      ],
      "metadata": {
        "id": "e-Xp--tKpIKk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Count Results    "
      ],
      "metadata": {
        "id": "IBX-HWNH0c2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Words counted    "
      ],
      "metadata": {
        "id": "4Y__6Vyl3fip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many words did we process?    \n",
        "*Remember that we skipped fluff words whenever we read them.*   "
      ],
      "metadata": {
        "id": "aa4GCqTx0v8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(sqrpegs_words_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIVSPocq_Wb",
        "outputId": "87681717-7301-4794-ab2d-c07f1d8dfadf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1723"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Descending order list of words by frequency    "
      ],
      "metadata": {
        "id": "RZc-qIwg3itl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a dictionary sorted in descending order by word count.    \n",
        "    \n",
        "We will use a `lambda` function to pass the `value` from `key:value` pairs to the `sorted()` keyword argument for the `key` to sort on.    \n",
        "\n",
        "In the following snippet of code:\n",
        " - The `sorted()` function takes three arguments -     \n",
        "   1. an iterable(dictionary) to sort    \n",
        "   2. `key=` specifies what value to use as a sort key (to sort by)    \n",
        "   3. `reverse=True` specifies that we want descending order    \n",
        "    \n",
        " - `lambda kv:kv[1]` takes the element in position 1 of the `key:value` tuple returned by the `.items()` method and provides that value to the `sorted()` argument for `key=`  \n",
        "     \n",
        "It can seem confusing that the term <b>*key*</b> here is used to refer to two different things:\n",
        " 1. The sort-by value for the `sorted()` function    \n",
        " 2. A `key` in the `key:value` pair of a dictionary     \n",
        "    \n",
        "Remember that the `.items()` method a **dictionary** returns the `key:value` pairs of that dictionary.  The tuples returned have `key` as the element in position 0, and the `value` as the element in position 1.     "
      ],
      "metadata": {
        "id": "IUI1lip_05lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sqrpegs_words_dict = dict(sorted(sqrpegs_words_dict.items(), key=lambda kv:kv[1], reverse=True))"
      ],
      "metadata": {
        "id": "Xfkz6j07uOpZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use **prettyprint** (`pprint.pprint`) to print our dictionary of words used in descending order.    "
      ],
      "metadata": {
        "id": "OkdUPxla3rB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(sorted_sqrpegs_words_dict)"
      ],
      "metadata": {
        "id": "f6mqunR9vQza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Words used more than ten times    \n"
      ],
      "metadata": {
        "id": "tB_qYbyz6WqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a conditional test in an assignment to take all of the words used more than ten times in the book (ignoring the fluff words) and store them in a new dictionary in descending order.    \n",
        "    \n",
        "Let's use **dictionary comprehension** to do this:        \n"
      ],
      "metadata": {
        "id": "gYRYu53L6c75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqrpegs_10x_words_dict = {k: v for k, v in sorted_sqrpegs_words_dict.items() if v > 10}"
      ],
      "metadata": {
        "id": "NCSaLLsR656_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then sort the resultant dictionary using `sorted()` again.    "
      ],
      "metadata": {
        "id": "CMy6_O8M-ara"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sqrpegs_10x_words_lst = sorted(sqrpegs_10x_words_dict.items(), key=lambda kv:kv[1], reverse=True)"
      ],
      "metadata": {
        "id": "JwSOXPZw-gCa"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(sorted_sqrpegs_10x_words_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmEYQSGn8sfS",
        "outputId": "5420f492-0a35-451c-d373-7623633c6a8a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('work', 48),\n",
            " ('all', 48),\n",
            " ('said', 40),\n",
            " ('lisabeth', 37),\n",
            " ('works', 33),\n",
            " ('john', 31),\n",
            " ('out', 30),\n",
            " ('electronic', 27),\n",
            " ('helen', 25),\n",
            " ('one', 25),\n",
            " ('catherine', 23),\n",
            " ('alice', 23),\n",
            " ('man', 22),\n",
            " ('foundation', 22),\n",
            " ('terms', 21),\n",
            " ('copyright', 20),\n",
            " ('insane', 20),\n",
            " ('room', 19),\n",
            " ('ship', 19),\n",
            " ('have', 18),\n",
            " ('people', 18),\n",
            " ('down', 18),\n",
            " ('up', 18),\n",
            " ('full', 18),\n",
            " ('states', 18),\n",
            " ('agreement', 18),\n",
            " ('about', 17),\n",
            " ('may', 16),\n",
            " ('license', 16),\n",
            " ('earth', 15),\n",
            " ('some', 15),\n",
            " ('donations', 15),\n",
            " ('will', 14),\n",
            " ('but', 14),\n",
            " ('must', 14),\n",
            " ('use', 13),\n",
            " ('back', 13),\n",
            " ('now', 13),\n",
            " ('here', 13),\n",
            " ('men', 13),\n",
            " ('united', 13),\n",
            " ('trademark', 13),\n",
            " ('literary', 13),\n",
            " ('archive', 13),\n",
            " ('well', 12),\n",
            " ('get', 12),\n",
            " ('see', 12),\n",
            " ('cried', 11),\n",
            " ('away', 11),\n",
            " ('oh', 11),\n",
            " ('copy', 11),\n",
            " ('paragraph', 11)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top-20 words used    "
      ],
      "metadata": {
        "id": "a1URSfUt32Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iachidyi35Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SFh2Fhwhnl9j"
      }
    }
  ]
}