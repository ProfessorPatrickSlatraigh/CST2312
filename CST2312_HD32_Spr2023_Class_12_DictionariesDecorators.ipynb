{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST2312/blob/main/CST2312_HD32_Spr2023_Class_12_DictionariesDecorators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sivi2IUlD10N"
      },
      "source": [
        "# **CST2312 Class12 - Dictionaries and Decorators**\n",
        "\n",
        "  - Word count with dictionaries    \n",
        "  - Anmol Tomar's Next Level Python on Decorators with a primer on foundational concepts used.     \n",
        "\n",
        "Updated content as of 07-Mar-2023   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtosZlQIczc0"
      },
      "source": [
        "*__*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dictionary Word Count Example     "
      ],
      "metadata": {
        "id": "4qmJFx9G0hcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Housekeeping    \n"
      ],
      "metadata": {
        "id": "Hrc_qewTl_6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string    # for string processing, including punctuation    \n",
        "import itertools # to take a slice of an iterable, including a dictionary slice\n",
        "import pprint    # for pretty printing of a dictionary   "
      ],
      "metadata": {
        "id": "MlrNg-rxmBx9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7fP5obdEAS3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Load and Handle    \n",
        "\n",
        "1. Take a copy of the UTF-8 text file of the book The Square Pegs by Ray Bradbury, 1948 from Professor Patrick's `data` repo on **GitHub** and load it to the current working directory with the file name `theSquarePegs.txt`.   \n",
        "\n",
        "2. Open a file handle `sqrpegs_handle` as *read-only* for the text file of the book.       "
      ],
      "metadata": {
        "id": "95SKQ_IsmC35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://raw.githubusercontent.com/ProfessorPatrickSlatraigh/data/main/theSquarePegs_RayBradbury.txt' -o 'theSquarePegs.txt'"
      ],
      "metadata": {
        "id": "YcECdC2omaJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioYbAlua1Ul"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate through the text    \n",
        "    \n",
        "* <u>Open the File</u>    \n",
        "1. With `open()` and skip to line #25    \n",
        "    \n",
        "* <u>Wrangle</u>\n",
        "2. Remove punctuation    \n",
        "3. Transform to lower case    \n",
        "4. Split wrangled lines into words    \n",
        "    \n",
        "* <u>Process words</u>    \n",
        "5. Drop words from fluff list of words\n",
        "6. Use dictionary and `.get()` to count instance of word    "
      ],
      "metadata": {
        "id": "d_11HjDcoU8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                                                           #5 build a list of fluff words to drop\n",
        "fluff_word_lst = ['the','to', 'of', 'and', 'a', 'in', 'you',\n",
        "                  'or', 'her', 'she', 'with', 'this', 'on',\n",
        "                  'it', 'for', 'was', 'not', 'i', 'is',\n",
        "                  'he', 'be', 'that', 'any', 'we', 'there',\n",
        "                  'are', 'at', 'by', 'from', 'do', 'be',\n",
        "                  'at', 'project', 'gutenberg',\n",
        "                  'gutenbergtm', 'they', 'as', 'them',\n",
        "                  'your', 'if', 'no', 'were',\n",
        "                  'an', 'into', 'us', 'where', 'what',\n",
        "                  'who', 'can', 'then', 'other', 'dont',\n",
        "                  'his', 'him', 'its', 'which', 'did']\n",
        "\n",
        "sqrpegs_words_dict = dict()                                 #6  initialize word count dictionary\n",
        "\n",
        "with open('/content/theSquarePegs.txt') as sqrpegs_handle:  #1  open the file\n",
        "    for skipped in range(25):                               #1  counting skipped lines\n",
        "        next(sqrpegs_handle)                                #1  skipping lines counted\n",
        "    for line_str in sqrpegs_handle:                         #   iterate lines to wrangle\n",
        "        # the following statement does the #2, #3, and #4 wrangling and split into a list of words \n",
        "        wrangled_words = line_str.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "        for word in wrangled_words:                         #   process lists of wrangled words\n",
        "            if word in fluff_word_lst:                      #5  drop fluff word\n",
        "                continue\n",
        "            sqrpegs_words_dict[word] = sqrpegs_words_dict.get(word, 0) +1  #6 keep a count in dictionary"
      ],
      "metadata": {
        "id": "e-Xp--tKpIKk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Count Results    "
      ],
      "metadata": {
        "id": "IBX-HWNH0c2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Words counted    "
      ],
      "metadata": {
        "id": "4Y__6Vyl3fip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many words did we process?    \n",
        "*Remember that we skipped fluff words whenever we read them.*   "
      ],
      "metadata": {
        "id": "aa4GCqTx0v8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(sqrpegs_words_dict)"
      ],
      "metadata": {
        "id": "LCIVSPocq_Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Descending order list of words by frequency    "
      ],
      "metadata": {
        "id": "RZc-qIwg3itl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a dictionary sorted in descending order by word count.    \n",
        "    \n",
        "We will use a `lambda` function to pass the `value` from `key:value` pairs to the `sorted()` keyword argument for the `key` to sort on.    \n",
        "\n",
        "In the following snippet of code:\n",
        " - The `sorted()` function takes three arguments -     \n",
        "   1. an iterable(dictionary) to sort    \n",
        "   2. `key=` specifies what value to use as a sort key (to sort by)    \n",
        "   3. `reverse=True` specifies that we want descending order    \n",
        "    \n",
        " - `lambda kv:kv[1]` takes the element in position 1 of the `key:value` tuple returned by the dictionary `.items()` method and provides that value to the `sorted()` argument for `key=`  \n",
        "     \n",
        "It can seem confusing that the term <b>*key*</b> here is used to refer to two different things:\n",
        " 1. The sort-by value for the `sorted()` function    \n",
        " 2. A `key` in the `key:value` pair of a dictionary     \n",
        "    \n",
        "Remember that the `.items()` method a **dictionary** returns the `key:value` pairs of that dictionary.  The tuples returned have `key` as the element in position 0, and the `value` as the element in position 1.     \n",
        "\n",
        "The tuples that are returned by `.items()` and then sorted by `sorted()` are an iterable of tuples which populate the list `sorted_sqrpegs_words_lst`.   "
      ],
      "metadata": {
        "id": "IUI1lip_05lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sqrpegs_words_lst = sorted(sqrpegs_words_dict.items(), key=lambda kv:kv[1], reverse=True)"
      ],
      "metadata": {
        "id": "Xfkz6j07uOpZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use **prettyprint** (`pprint.pprint`) to print our list of words used in descending order.    "
      ],
      "metadata": {
        "id": "OkdUPxla3rB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(sorted_sqrpegs_words_lst)"
      ],
      "metadata": {
        "id": "f6mqunR9vQza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Words used more than ten times    \n"
      ],
      "metadata": {
        "id": "tB_qYbyz6WqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a conditional test in an assignment to take all of the words used more than ten times in the book (ignoring the fluff words) and store them in a new dictionary in descending order.    \n",
        "    \n",
        "Let's use **dictionary comprehension** to do this:        \n"
      ],
      "metadata": {
        "id": "gYRYu53L6c75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqrpegs_10x_words_dict = {k: v for k, v in sqrpegs_words_dict.items() if v > 10}"
      ],
      "metadata": {
        "id": "NCSaLLsR656_"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then sort the resultant dictionary using `sorted()` again.    "
      ],
      "metadata": {
        "id": "CMy6_O8M-ara"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sqrpegs_10x_words_lst = sorted(sqrpegs_10x_words_dict.items(), key=lambda kv:kv[1], reverse=True)"
      ],
      "metadata": {
        "id": "JwSOXPZw-gCa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(sorted_sqrpegs_10x_words_lst)"
      ],
      "metadata": {
        "id": "TmEYQSGn8sfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top-20 words used    "
      ],
      "metadata": {
        "id": "a1URSfUt32Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we go back to the list `sorted_sqrpegs_words_lst` that contains tuples of `key:value` pair data sorted in descending order by `value` then we can easily identify the top-20 words used in the book (ignoring fluff words) by taking a slice of the first twenty elements in the list:    "
      ],
      "metadata": {
        "id": "Iachidyi35Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(sorted_sqrpegs_words_lst[:20])"
      ],
      "metadata": {
        "id": "0_qCADfAEah7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top-20 words usage as a percentage of total words    "
      ],
      "metadata": {
        "id": "R3KprLhYEyd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we wanted to know what percentage of the total (non-fluff) words for each of the top-20 words used in the book?    "
      ],
      "metadata": {
        "id": "3OBuYMmOE4uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in sorted_sqrpegs_words_lst[:20]:\n",
        "    word_pct = '{:.2f}'.format(count/len(sqrpegs_words_dict)*100)  # calculate the percentage to 2 decimal places\n",
        "    print(f'\"{word}\" is used {count} times, which is {word_pct} percent of the total words.')  # print the 3 variables"
      ],
      "metadata": {
        "id": "Nd-caQWoFK87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "f6cCJCfJEn0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Level Python (continued): Decorators     \n"
      ],
      "metadata": {
        "id": "6POF_PObIGpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SFh2Fhwhnl9j"
      }
    }
  ]
}